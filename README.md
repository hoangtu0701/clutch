# ğŸ® Clutch

ğŸ™ï¸ **Clutch** is a real-time voice assistant and tactical AI coach for Counter-Strike 2.

It listens to your voice, analyzes your game state (via GSI + screenshots), and responds with round-winning advice using AI models â€” all spoken back in real time.

---

## ğŸ¥ Demo

https://github.com/user-attachments/assets/c0977d21-d7a4-49e0-9168-cdaa2423d8c9

---

## âœ¨ Features

- ğŸ”Š Wakeword detection â€” just say **"Hey Jarvis"**
- ğŸ™ï¸ Real-time speech transcription (STT)
- ğŸ§  Tactical advice powered by streaming LLMs
- ğŸ“¸ GSI + screenshot parsing for contextual awareness
- ğŸ—£ï¸ **TTS pipeline with smart fallback**  
  - Primary: **Google Chirp 3 HD (streaming)** if a Google key is present  
  - Fallbacks: **Piper** (low-VRAM) or **Coqui XTTS v2** (high-VRAM) â€” chosen automatically
- â± **In-round timer badge** with auto-detection for freezetime, live, bomb plant, and round end
- ğŸ–¼ï¸ **Multi-region screen capture** (radar + alive counters) to boost tactical precision
- ğŸªŸ **Desktop UI** (PyQt) with live badges for TTS engine and round timer
- ğŸ—‚ï¸ **Secret keys folder** for simple, portable configuration
- ğŸ› ï¸ **Auto GSI setup**: copies `gamestate_integration_clutch.cfg` to your CS2 `cfg` folder if missing

---

## ğŸ“ Project Structure

```
clutch/
â”œâ”€â”€ clutch_loop.py                      # Main runtime loop (voice â†’ context â†’ AI â†’ voice)
â”œâ”€â”€ requirements.txt                    # All pip packages required (generated via pip freeze)
â”œâ”€â”€ models/                             # TTS & STT models (must download via Google Drive)
â”‚   â”œâ”€â”€ Coqui/                          # XTTS model files
â”‚   â”œâ”€â”€ Piper/                          # Piper runtime + voice (.onnx + .json)
â”‚   â””â”€â”€ tiny.en/                        # OpenWakeWord + STT model
â”œâ”€â”€ gamestate_integration_clutch.cfg    # GSI config (auto-copied into CS2 directory)
â”œâ”€â”€ secret_keys/                        # Store keys here (see setup)
â”‚   â”œâ”€â”€ openai.key
â”‚   â”œâ”€â”€ openrouter.key                  # optional (not used right now)
â”‚   â””â”€â”€ google_tts_key.json             # optional (enables Google TTS streaming)
â”œâ”€â”€ venv/                               # To-be-installed packages & Python environment
```
---

## âš™ï¸ Setup Instructions (Windows Only)

### 1. Clone the repo

```bash
git clone https://github.com/hoangtu0701/clutch.git
cd clutch
```

### 2. Set up Python environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3. Install all dependencies

```bash
pip install -r requirements.txt
```

> âš ï¸ This installs everything exactly as used in development (from `pip freeze`).

### 4. Create your `secret_keys` folder

Create a folder at the project root named `secret_keys/` with up to **three** files:

```
secret_keys/
â”œâ”€â”€ openai.key                # REQUIRED: paste your OpenAI API key (just the key string)
â”œâ”€â”€ openrouter.key            # OPTIONAL: not needed right now
â””â”€â”€ google_tts_key.json       # OPTIONAL: paste your service account JSON to enable Google TTS streaming
```

- If **`google_tts_key.json` is missing**, Clutch will **automatically** use local TTS: Piper (for low VRAM) or Coqui XTTS (for high VRAM).
- If **`openai.key` is missing**, the app cannot call the model and wonâ€™t work.

> â³ **Heads-up:** first startup can take a bit (model + audio warmup). Leave the window alone for ~30s on first run.

---

## ğŸ“¦ Download Required Models

The following folder is **not included** in the GitHub repo due to size limits.

ğŸ“¥ Download from Google Drive:  
ğŸ‘‰ [Clutch folders](https://drive.google.com/drive/folders/1wAPdx7JF7OL3bMVblcqT-djFfrwNv_vB?usp=sharing)

Youâ€™ll get:

```
models/
â”œâ”€â”€ Coqui/       # Coqui XTTS model files (e.g., model.pth, config.json)
â”œâ”€â”€ Piper/       # Piper runtime + a voice, e.g.:
â”‚   â”œâ”€â”€ piper/piper.exe
â”‚   â”œâ”€â”€ en_US-norman-medium.onnx
â”‚   â””â”€â”€ en_US-norman-medium.onnx.json
â”œâ”€â”€ tiny.en/     # Wakeword + transcription models
```

Place the whole models/ folder inside your Clutch project directory.

---

## ğŸš€ Run Clutch

Once everything is installed and models are in place:

```bash
python clutch_loop.py
```

Say **â€œHey Jarvisâ€**, then start talking. Clutch will:

- Capture your speech + game context (CS2 GSI + screenshot)
- Analyze everything with LLMs
- Respond instantly with tactical voice coaching

> ğŸ’¡ While Clutch is speaking, you can say **â€œHey Jarvisâ€** again to interrupt and ask something new.

---

## ğŸ§© Notes & Troubleshooting

- **GSI auto-setup:** on first run, the app tries to copy `gamestate_integration_clutch.cfg` into your CS2 `cfg` folder. If it fails, run the app as admin and/or copy it manually.
- **TTS selection:** with no Google key, Clutch auto-picks **Piper** if your GPU has low VRAM (â‰ˆ <12GB) or **Coqui XTTS** if thereâ€™s plenty.
- **Round timer badge:** shows `mm:ss` and auto-switches to a bomb timer when planted.
- **Screenshots:** only captured if a visible â€œCounter-Strike 2â€ window is found on your desktop.

---
